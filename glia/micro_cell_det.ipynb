{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion correction and cells detection\n",
    "---\n",
    "\n",
    "Microglia cells with tdTomato + GCamp5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "try:\n",
    "    cv2.setNumThreads(8)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.source_extraction.cnmf import utilities as util\n",
    "\n",
    "from skimage.util import montage\n",
    "from skimage.filters import rank\n",
    "from skimage import morphology\n",
    "from skimage import exposure\n",
    "from skimage import measure\n",
    "\n",
    "from scipy.ndimage import measurements\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_name = 'F7'\n",
    "samp_path = os.path.join(''.join(sys.path[0].split('glia')), 'data_glia', samp_name)\n",
    "\n",
    "# sample YAML metadata file uploading\n",
    "with open(f'{samp_path}/{samp_name}_meta.yaml') as f:\n",
    "    samp_meta = yaml.safe_load(f)\n",
    "\n",
    "file_raw = f'{samp_path}/{samp_name}_ca.tif'\n",
    "file_memmap = f'{samp_path}/F7_memmap_d1_512_d2_512_d3_1_order_C_frames_1500.mmap'\n",
    "file_fit = f'{samp_path}/{samp_name}_fit.hdf5'\n",
    "file_refit = f'{samp_path}/{samp_name}_refit.hdf5'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CaImAn parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data params\n",
    "ca_path = [file_raw]\n",
    "fr = 1                      # imaging rate in frames per second\n",
    "decay_time = 3              # length of a typical transient in seconds (see source/Getting_Started.rst)\n",
    "dxy = (0.311, 0.311)        # spatial resolution of FOV in pixels per um\n",
    "\n",
    "# patch params\n",
    "rf =  50                    # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride = 10                 # amount of overlap between the patches in pixels\n",
    "\n",
    "# pre-peocess params\n",
    "noise_method = 'logmexp'     # PSD averaging method for computing the noise std\n",
    "only_init = False\n",
    "\n",
    "# motion correction params\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "max_shifts = (10, 10)       # maximum allowed rigid shifts (in pixels)\n",
    "strides = (80, 80)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (20, 20)         # overlap between pathes (size of patch strides+overlaps)\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# init params\n",
    "K = 4                            # number of components to be found (per patch or whole FOV depending on whether rf=None)\n",
    "gSig = [15, 15]                  # radius of average spatial components (in pixels)\n",
    "ssub = 5                         # spatial subsampling during initialization\n",
    "tsub = 2                         # temporal subsampling during intialization\n",
    "method_init = 'greedy_roi'       # initialization method ('sparse_nmf' NOT WORKING!),   'graph_nmf'\n",
    "seed_method = 'auto'             # methods for choosing seed pixels during greedy_roi or corr_pnr initialization\n",
    "\n",
    "# merge params\n",
    "merge_thr = 0.1                  # trace correlation threshold for merging two components.\n",
    "merge_parallel = True            # perform merging in parallel\n",
    "\n",
    "# spatial and temporal params\n",
    "nb = 2                           # number of global background components\n",
    "method_deconvolution = 'oasis'   # method for solving the constrained deconvolution problem ('oasis','cvx' or 'cvxpy') if method cvxpy, primary and secondary (if problem unfeasible for approx solution)\n",
    "noise_range = [0.25, 0.5]        # range of normalized frequencies over which to compute the PSD for noise determination\n",
    "noise_method = 'logmexp'         # PSD averaging method for computing the noise std\n",
    "p = 2                            # order of the autoregressive system\n",
    "\n",
    "# quality params\n",
    "min_SNR = 5                      # trace SNR threshold. Traces with SNR above this will get accepted\n",
    "SNR_lowest = 2                   # minimum required trace SNR. Traces with SNR below this will get rejected\n",
    "rval_thr = 0.65                  # space correlation threshold. Components with correlation higher than this will get accepted                 \n",
    "rval_lowest = -2                 # minimum required space correlation. Components with correlation below this will get rejected\n",
    "use_cnn = False                  # flag for using the CNN classifier\n",
    "\n",
    "\n",
    "param_dict = {'fnames': ca_path,\n",
    "              'fr': fr,\n",
    "              'decay_time': decay_time,\n",
    "              'dxy': dxy,\n",
    "              'rf': rf,\n",
    "              'stride': stride,\n",
    "              'noise_method': noise_method,\n",
    "              'only_init': only_init,\n",
    "              'max_deviation_rigid': max_deviation_rigid,\n",
    "              'max_shifts': max_shifts,\n",
    "              'strides': strides,\n",
    "              'overlaps': overlaps,\n",
    "              'pw_rigid': pw_rigid,\n",
    "              'K': K,\n",
    "              'gSig': gSig,\n",
    "              'ssub': ssub,\n",
    "              'tsub': tsub,\n",
    "              'method_init': method_init,\n",
    "              'seed_method': seed_method,\n",
    "              'merge_thr': merge_thr,\n",
    "              'merge_parallel': merge_parallel,\n",
    "              'nb': nb,\n",
    "              'method_deconvolution': method_deconvolution,\n",
    "              'noise_range': noise_range,\n",
    "              'noise_method': noise_method,\n",
    "              'p': p,\n",
    "              'min_SNR': min_SNR,\n",
    "              'SNR_lowest': SNR_lowest,\n",
    "              'rval_thr': rval_thr,\n",
    "              'rval_lowest': rval_lowest,\n",
    "              'use_cnn': use_cnn}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=param_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion correction\n",
    "*if there is no existing memmap*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True - Ca channel demostration on\n",
    "display_movie = True\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(ca_path)\n",
    "    ds_ratio = 0.31\n",
    "    m_orig.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=100, magnification=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "mc = MotionCorrect(ca_path, dview=dview, **opts.get_group('motion'))\n",
    "\n",
    "mc.motion_correct(save_movie=samp_path)\n",
    "m_els = cm.load(mc.fname_tot_els)\n",
    "border_to_0 = 0 if mc.border_nan == 'copy' else mc.border_to_0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results\n",
    "display_movie = True\n",
    "save_avi = True\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(ca_path)\n",
    "    ds_ratio = 0.2\n",
    "    cm.concatenate([m_orig.resize(1, 1, ds_ratio) - mc.min_mov*mc.nonneg_movie,\n",
    "                    m_els.resize(1, 1, ds_ratio)], \n",
    "                   axis=2).play(fr=30, q_max=99.5, magnification=1, offset=0, save_movie=save_avi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory map the file in order 'C' saving\n",
    "ca_new = cm.save_memmap(mc.mmap_file, base_name=f'{samp_name}_memmap_', order='C',\n",
    "                        border_to_0=border_to_0) # exclude borders\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNMF fit & refit\n",
    "\n",
    "*if there is no existing refited CNMF*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## memmap loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(file_memmap, str):\n",
    "    Yr, dims, T = cm.load_memmap(file_memmap)\n",
    "else:\n",
    "    cm.load_memmap(ca_new)\n",
    "\n",
    "ca_images = np.reshape(Yr.T, [T] + list(dims), order='F') \n",
    "Cn = cm.local_correlations(ca_images, swap_dim=False)\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(Cn, cmap='magma')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "if isinstance(file_fit, str):\n",
    "    cnm = cnmf.load_CNMF(file_fit, n_processes=1, dview=dview)\n",
    "else:   \n",
    "    cnm = cnm.fit(ca_images)\n",
    "    save_results = True\n",
    "    if save_results:\n",
    "        cnm.save(f'{samp_path}/{samp_name}_fit.hdf5')\n",
    "\n",
    "cnm.estimates.plot_contours_nb(img=Cn, cmap='magma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.evaluate_components(ca_images, cnm.params, dview=dview)\n",
    "\n",
    "min_size = 100              # minimal component area in px\n",
    "max_size = 512^2             # maximal component area in px\n",
    "\n",
    "cnm.estimates.threshold_spatial_components(maxthr=0.3, dview=dview)\n",
    "cnm.estimates.remove_small_large_neurons(min_size_neuro=min_size, max_size_neuro=max_size)\n",
    "cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components, cmap='magma')\n",
    "\n",
    "print(f'{len(cnm.estimates.idx_components)} good components: {cnm.estimates.idx_components}')\n",
    "print(f'{len(cnm.estimates.idx_components_bad)} bad components: {cnm.estimates.idx_components_bad}')\n",
    "\n",
    "# cnm.estimates.select_components(idx_components=cnm.estimates.idx_components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(file_refit, str):\n",
    "    cnm2 = cnmf.load_CNMF(file_refit, n_processes=1, dview=dview)\n",
    "else:   \n",
    "    cnm2 = cnm.refit(ca_images, dview=dview)\n",
    "\n",
    "    save_results = True\n",
    "    if save_results:\n",
    "        cnm2.save(f'{samp_path}/{samp_name}_refit.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% restart cluster to clean up memory\n",
    "cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.evaluate_components(ca_images, cnm.params, dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm.estimates.plot_contours_nb(img=Cn, idx=cnm.estimates.idx_components, cmap='magma')\n",
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components, cmap='magma')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final CNMF selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_cnm = cnm2\n",
    "print(fin_cnm.estimates.idx_components)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot & output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dF_cascade_plot(prof_arr, y_shift=0.5):\n",
    "    \"\"\" prof_arr, [prof_num, prof_val] - 2d numpy array with dF/F profiles\n",
    "\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    shift = 0\n",
    "    for i in prof_arr:\n",
    "        plt.plot(i+shift, alpha=.5)\n",
    "        shift += y_shift\n",
    "    plt.vlines(x=[-20], ymin=[-0.2], ymax=[0.8], linewidth=3, color='k')\n",
    "    plt.text(x=-60, y=-0.1, s=\"100% ﾎ認/F\", size=15, rotation=90.)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def comp_mask_plot(samp_cnmf, samp_img):\n",
    "    \"\"\" All spatial components (A) mask ctrl img\n",
    "\n",
    "    \"\"\"\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "    all_A = np.zeros_like(A[0])\n",
    "\n",
    "    component_centers = {}\n",
    "    for i in samp_cnmf.estimates.idx_components:  # range(A_shape[0]):\n",
    "        A_frame = A[i]\n",
    "        A_frame != 0\n",
    "        component_centers.update({i:np.asarray(measurements.center_of_mass(A_frame), dtype=int)})\n",
    "        all_A[np.array(A_frame, dtype=bool)] = i\n",
    "\n",
    "    all_A = np.ma.masked_where(all_A == 0, all_A, copy=False)\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(samp_img, cmap='magma')\n",
    "    plt.imshow(all_A, cmap='jet', alpha=.5)\n",
    "    for component_num in component_centers.keys():\n",
    "        center_coord = component_centers[component_num]\n",
    "        plt.annotate(component_num+1, # this is the value which we want to label (text)\n",
    "                    (center_coord[1], center_coord[0]), # x and y is the points location where we have to label\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(2,2),\n",
    "                    ha='center',\n",
    "                    color='white')\n",
    "    plt.show()\n",
    "\n",
    "def comp_contour_plot(samp_cnmf, samp_img):\n",
    "    \"\"\" All spatial components (A) contours overlap ctrl img\n",
    "\n",
    "    https://stackoverflow.com/questions/28779559/how-to-set-same-color-for-markers-and-lines-in-a-matplotlib-plot-loop\n",
    "\n",
    "    \"\"\"\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(samp_img, cmap='magma')\n",
    "    ax = plt.gca()\n",
    "\n",
    "    for i in samp_cnmf.estimates.idx_components: \n",
    "        A_frame = A[i]\n",
    "        A_frame[A_frame != 0] = 1\n",
    "        A_frame = np.ma.masked_where(A_frame == 0, A_frame, copy=False)\n",
    "        A_center = measurements.center_of_mass(A_frame)\n",
    "        A_contour = np.asarray(measure.find_contours(A_frame, level=0.5))\n",
    "\n",
    "        plt.imshow(A_frame, cmap='jet', alpha=.5)\n",
    "        color = next(ax._get_lines.prop_cycler)['color']\n",
    "        for cont in A_contour:            \n",
    "            plt.plot(cont[:, 1], cont[:, 0], linewidth=2, color=color)\n",
    "        plt.annotate(f'ROI {i+1}',\n",
    "                    (A_center[1], A_center[0]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(2,2),\n",
    "                    ha='center',\n",
    "                    color='white',\n",
    "                    weight='bold',\n",
    "                    fontsize=10)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def comp_dF_plot(samp_cnmf, y_shift=0.5):\n",
    "    plt.figure(figsize=(20, 8))\n",
    "\n",
    "    shift = 0\n",
    "    for i in samp_cnmf.estimates.idx_components:\n",
    "        df_prof = samp_cnmf.estimates.F_dff[i]\n",
    "        plt.plot(df_prof+shift, alpha=.5, label=f'ROI {i+1}')\n",
    "        shift -= y_shift\n",
    "\n",
    "    plt.vlines(x=[-20], ymin=[-0.2], ymax=[0.8], linewidth=3, color='k')\n",
    "    plt.text(x=-60, y=-0.5, s=\"100% ﾎ認/F\", size=15, rotation=90.)\n",
    "    plt.axis('off')\n",
    "    plt.legend(loc=1)\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ﾎ認/F calc & ctrl plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_cnm.estimates.detrend_df_f(quantileMin=5, frames_window=500,\n",
    "                            flag_auto=True, use_fast=False, detrend_only=False)\n",
    "\n",
    "comp_contour_plot(fin_cnm, Cn)\n",
    "comp_dF_plot(fin_cnm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output CSV saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prof_df(samp_cnmf, samp_img, reg_time, samp_name, samp_path):\n",
    "    A = samp_cnmf.estimates.A.toarray().reshape(samp_img.shape[1:] + (-1,), order='F').transpose([2, 0, 1])\n",
    "\n",
    "    # init df\n",
    "    output_df = pd.DataFrame(columns=['reg_name',      # registration name\n",
    "                                      'index',         # frame index\n",
    "                                      'time',          # registration time\n",
    "                                      'comp',          # component num\n",
    "                                      'profile_raw',   # component raw value, total mean\n",
    "                                      'profile_C',     # component denoised value\n",
    "                                      'profile_ddf'])   # component detrended ﾎ認/F value\n",
    "    \n",
    "    frame_num = samp_cnmf.estimates.C.shape[1]\n",
    "    i_col = range(frame_num)\n",
    "    time_col = np.linspace(0, reg_time, num=frame_num)\n",
    "    reg_name_col = np.full(frame_num, samp_name)\n",
    "\n",
    "    for component_num in samp_cnmf.estimates.idx_components:\n",
    "        component_col = np.full(ca_images.shape[0], component_num)\n",
    "        \n",
    "        A_frame = A[component_num]\n",
    "        A_mask = np.copy(A_frame)\n",
    "        A_mask != 0\n",
    "        A_mask = np.array(A_mask, dtype=bool)\n",
    "\n",
    "        # mean by spatial component mask\n",
    "        est_raw = np.asarray([np.mean(np.ma.masked_where(~A_mask, frame)) for frame in samp_img])\n",
    "\n",
    "        # temporal component\n",
    "        est_C = samp_cnmf.estimates.C[component_num]\n",
    "\n",
    "        # detrended temporal component\n",
    "        est_df = samp_cnmf.estimates.F_dff[component_num]\n",
    "        \n",
    "        component_df = pd.DataFrame({'reg_name':reg_name_col,\n",
    "                                     'index':i_col,\n",
    "                                     'time':time_col,\n",
    "                                     'comp':component_col,\n",
    "                                     'profile_raw':est_raw,\n",
    "                                     'profile_C':est_C,\n",
    "                                     'profile_ddf':est_df})\n",
    "        output_df = pd.concat([output_df, component_df], ignore_index=True)\n",
    "\n",
    "    output_df.to_csv(f'{samp_path}/{samp_name}_components_df.csv', index=False)\n",
    "    print(output_df.head())\n",
    "\n",
    "save_prof_df(samp_cnmf=fin_cnm,\n",
    "             samp_img=ca_images,\n",
    "             samp_name=samp_name,\n",
    "             samp_path=samp_path, \n",
    "             reg_time=samp_meta['Reg_time'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff stuff\n",
    "\n",
    "# cnm.estimates.play_movie(ca_images, q_max=95, magnification=1, include_bck=False, use_color=True, save_movie=True)\n",
    "\n",
    "# time-series correlation: https://towardsdatascience.com/four-ways-to-quantify-synchrony-between-time-series-data-b99136c4a9c9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "29b2b70970d54890c2ecd25b23b96024fbcef9a6a76cf3bb8bb780f56e497e25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
